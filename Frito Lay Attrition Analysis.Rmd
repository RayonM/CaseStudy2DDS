---
title: "Frito Lay Analysis"
author: "Rayon M"
date: "7/30/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## **Project Objectives**

  1.  Classify Attrition
  2.  Identify Trends within the Departments and Job Roles
  3.  Predict Monthly Income

## **Methodology**

  To arrive at my final conclusions, I used the following methodology:
  
  1.  Loaded the data set provided (CaseStudy2-data.csv)
  2.  Performed Exploratory Data Analysis to identify key factors that leads to Attrition, and find explanatory variables for the Linear Regression Model.
  3.  Used the Naive Bayes to achieve Classification
  4.  Used Linear Regression to Predict the Monthly Income



```{r echo = FALSE}

# Import the relevant packages  Libraries Used in the Study


library(tidyverse)
library(GGally)
library(naniar)
library(dplyr)
library(class)
library(caret)
library(e1071)
library(ggplot2)
library(plotly)


```



```{r echo=FALSE}

# Read in the employee dataset that will be used in the Analysis.
employee_data = read.csv("C:/Users/Rayon/OneDrive/Documents/Doing DataScience/Doing Data Science/MSDS_6306_Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2-data.csv")


```


# **Classification Model**
## Naive Bayes

```{r}

# Find the average accuracy, sensitivity, and specificity of the model. The sensitivity and specificity must both be above 60%.

master_acc = numeric(100)
master_sensitivity = numeric(100)
master_specificivity = numeric(100)
master_seed = numeric(100)


for(seed in 1:100)
{
  set.seed(seed)
  splitPerc = 0.70
  TrainIndices = sample(1:dim(employee_data)[1],round(splitPerc * dim(employee_data)[1]))
  Train = employee_data[TrainIndices,]
  Test = employee_data[-TrainIndices,]
  model_attrition_yesorno = naiveBayes(Train[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")],factor(Train$Attrition, labels=c("No", "Yes")))
  CM = confusionMatrix(table(factor(Test$Attrition, labels = c("No", "Yes")), predict(model_attrition_yesorno,Test[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")])))
  master_acc[seed] = CM$overall[1]
  master_sensitivity[seed] = CM$byClass[1]
  master_specificivity[seed] = CM$byClass[2]
  master_seed[seed] = seed
}

mean(master_seed)
mean(master_acc)
mean(master_sensitivity)
mean(master_specificivity)


# The mean Accuracy is 0.8544061
# The mean Sensitivity is 0.8688525
# The mean Specificity is 0.6470588

```

## Competition dataset with No Attrition. Use the Naive Bayes Model to predict Attrition.

```{r echo = FALSE}
#Load in the competition dataset
comp_dataset = read.csv("C:/Users/Rayon/OneDrive/Documents/Doing DataScience/Doing Data Science/MSDS_6306_Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2CompSet No Attrition.csv")

#Use the Naive Bayes Classification Model to classify each observation as Yes or No to Attrition.
# Model name = "model_attrition_yesorno"

comp_dataset$Attrition =  predict(model_attrition_yesorno,comp_dataset[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")])

view(comp_dataset)

write.csv(comp_dataset, "Case2PredictionsMorris Attrition.csv")

```


# Regression Model to predict MonthlyIncome
```{r}
#MSPE - Mean squared prediction error 
#MSE = Sum of ((y - ybar)^2)/n
#RMSE = square root of the MSE
# standard deviation


#Goal, create a regression model that has an RMSE less than $3000

# Dependent Variable: MonthlyIncome
# Predictors/Experiment variable(s): Age and Total Working Years

# Plot the following variables to see the correlation with MonthlyIncome

# employeeData %>% select(MonthlyIncome, Age, Department, EducationField, JobLevel, JobRole, TotalWorkingYears, YearsAtCompany) %>%
# ggpairs()

## Age and Total Working Years had the best fit.

#plot a the linear regression graph of TotalWorkingYears vs. MonthlyIncome



#Train the Model

numMSPEs = 1000
MSPEHolderModel1 = numeric(numMSPEs)
MSPEHolderModel2 = numeric(numMSPEs)
MSPEHolderModel3 = numeric(numMSPEs)
MSPEHolderModel4 = numeric(numMSPEs)
MSPEHolderModel5 = numeric(numMSPEs)
MSPEHolderModel6 = numeric(numMSPEs)
MSPEHolderModel7 = numeric(numMSPEs)
MSPEHolderModel8 = numeric(numMSPEs)
MSPEHolderModel9 = numeric(numMSPEs)
MSPEHolderModel10 = numeric(numMSPEs)
MSPEHolderModel11 = numeric(numMSPEs)
MSPEHolderModel12 = numeric(numMSPEs)
MSPEHolderModel13 = numeric(numMSPEs)
MSPEHolderModel14 = numeric(numMSPEs)
MSPEHolderModel15 = numeric(numMSPEs)
MSPEHolderModel16 = numeric(numMSPEs)
MSPEHolderModel17 = numeric(numMSPEs)
MSPEHolderModel18 = numeric(numMSPEs)

for (i in 1:numMSPEs)
{
  
  index <- createDataPartition(employee_data$ID, p = .60, list = FALSE)
  monthly_income_train <- employee_data[index, ]
  monthly_income_test <- employee_data[-index, ]
  
  dim(monthly_income_test)
  dim(monthly_income_train)
  
  #Model 1
  
  monthly_income_model_fit1 = lm(MonthlyIncome ~ Age, data = monthly_income_train)
  monthly_income_Pred_1 = predict(monthly_income_model_fit1, newdata = monthly_income_test)
  
  MSPE1 = mean((employee_data$MonthlyIncome - monthly_income_Pred_1)^2)
  MSPE1
  MSPEHolderModel1[i] = MSPE1
  
  #Model 2
  monthly_income_model_fit2 = lm(MonthlyIncome ~ Department, data = monthly_income_train)
  monthly_income_Pred_2 = predict(monthly_income_model_fit2, newdata = monthly_income_test)
  MSPE2 = mean((employee_data$MonthlyIncome - monthly_income_Pred_2)^2)
  MSPE2
  MSPEHolderModel2[i] = MSPE2
  
  #Model 3
  monthly_income_model_fit3 = lm(MonthlyIncome ~ EducationField, data = monthly_income_train)
  monthly_income_Pred_3 = predict(monthly_income_model_fit3, newdata = monthly_income_test)
  MSPE3 = mean((employee_data$MonthlyIncome - monthly_income_Pred_3)^2)
  MSPE3
  MSPEHolderModel3[i] = MSPE3
  
  
  #Model 4
  monthly_income_model_fit4 = lm(MonthlyIncome ~ JobLevel, data = monthly_income_train)
  monthly_income_Pred_4 = predict(monthly_income_model_fit4, newdata = monthly_income_test)
  MSPE4 = mean((employee_data$MonthlyIncome - monthly_income_Pred_4)^2)
  MSPE4
  MSPEHolderModel4[i] = MSPE4
  
  #Model 5
  monthly_income_model_fit5 = lm(MonthlyIncome ~ JobRole, data = monthly_income_train)
  monthly_income_Pred_5 = predict(monthly_income_model_fit5, newdata = monthly_income_test)
  MSPE5 = mean((employee_data$MonthlyIncome - monthly_income_Pred_5)^2)
  MSPE5
  MSPEHolderModel5[i] = MSPE5
  
  
  #Model 6
  monthly_income_model_fit6 = lm(MonthlyIncome ~ TotalWorkingYears, data = monthly_income_train)
  monthly_income_Pred_6 = predict(monthly_income_model_fit6, newdata = monthly_income_test)
  MSPE6 = mean((employee_data$MonthlyIncome - monthly_income_Pred_6)^2)
  MSPE6
  MSPEHolderModel6[i] = MSPE6
  
  
  #Model 7
  monthly_income_model_fit7 = lm(MonthlyIncome ~ YearsAtCompany, data = monthly_income_train)
  monthly_income_Pred_7 = predict(monthly_income_model_fit7, newdata = monthly_income_test)
  MSPE7 = mean((employee_data$MonthlyIncome - monthly_income_Pred_7)^2)
  MSPE7
  MSPEHolderModel7[i] = MSPE7
  
  
  #Model 8
  monthly_income_model_fit8 = lm(MonthlyIncome ~ Age+Department+EducationField+JobLevel+JobRole+TotalWorkingYears+YearsAtCompany, data = monthly_income_train)
  monthly_income_Pred_8 = predict(monthly_income_model_fit8, newdata = monthly_income_test)
  MSPE8 = mean((employee_data$MonthlyIncome - monthly_income_Pred_8)^2)
  MSPE8
  MSPEHolderModel8[i] = MSPE8
  
 
  #Model 9
  monthly_income_model_fit9 = lm(MonthlyIncome ~ JobRole+JobLevel+TotalWorkingYears, data = monthly_income_train)
  monthly_income_Pred_9 = predict(monthly_income_model_fit9, newdata = monthly_income_test)
  MSPE9 = mean((employee_data$MonthlyIncome - monthly_income_Pred_9)^2)
  MSPE9
  MSPEHolderModel9[i] = MSPE9

 
  #Model 10
  # monthly_income_test %>% ggplot(mapping = aes(x = MonthlyIncome, y = TotalWorkingYears))+ 
  # geom_point()
  monthly_income_test_mutate <- employee_data %>% mutate(TotalWorkingYears2 = TotalWorkingYears^2)
  monthly_income_model_fit10 = lm(MonthlyIncome~TotalWorkingYears+TotalWorkingYears2, data = monthly_income_test_mutate)
  monthly_income_Pred_10 = predict(monthly_income_model_fit10, newdata = monthly_income_test_mutate)
  MSPE10 = mean((employee_data$MonthlyIncome - monthly_income_Pred_10)^2)
  MSPE10
  MSPEHolderModel10[i] = MSPE10

}

mean(MSPEHolderModel1)
mean(MSPEHolderModel2)
mean(MSPEHolderModel3)
mean(MSPEHolderModel4)
mean(MSPEHolderModel5)
mean(MSPEHolderModel6)
mean(MSPEHolderModel7)
mean(MSPEHolderModel8)
mean(MSPEHolderModel9)
mean(MSPEHolderModel10)
# mean(MSPEHolderModel11)
# mean(MSPEHolderModel13)
# mean(MSPEHolderModel14)
# mean(MSPEHolderModel15)
# mean(MSPEHolderModel16)
# mean(MSPEHolderModel17)
# mean(MSPEHolderModel18)



```

## Competition dataset with No MonthlyIncome. Use the Linear Regression Model to predict Monthly Income.

```{r}
#Load in the competition dataset
monthly_income_comp_dataset = read.csv("C:/Users/Rayon/OneDrive/Documents/Doing DataScience/Doing Data Science/MSDS_6306_Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2CompSet No Salary.csv")

#Use the Linear Regression Model to predict the MonthlyIncome for each observation.
# Model name = "model_attrition_yesorno"

#monthly_income_comp_dataset$PredMonthlyIncome =  predict(model_attrition_yesorno,comp_dataset[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")])

#view(monthly_income_comp_dataset)

#write.csv(monthly_income_comp_dataset, "Case2PredictionsMorris Salary.csv")

```



# Summary of the Models

```{r}
summary(monthly_income_model_fit1) # Age Not a Good Fit
confint(monthly_income_model_fit1)
  
summary(monthly_income_model_fit2) # Department - Not a good fit
confint(monthly_income_model_fit2)

summary(monthly_income_model_fit3) #EducationField - Slightly good.
confint(monthly_income_model_fit3)

summary(monthly_income_model_fit4) # JobLevel Good Fit! - It has a RMSE of 1414
confint(monthly_income_model_fit4)

summary(monthly_income_model_fit5) # Slightly good fit - RMSE of 2044
confint(monthly_income_model_fit5)

summary(monthly_income_model_fit6) # Great fit - RMSE of 2826
confint(monthly_income_model_fit6)
monthly_income_test %>% ggplot(aes(x = MonthlyIncome, y = TotalWorkingYears)) + 
  geom_point() +
  geom_line(data = monthly_income_test, aes( x = MonthlyIncome, y = monthly_income_Pred_6, col = "red"))


summary(monthly_income_model_fit7) # YearsatCompany Good fit
confint(monthly_income_model_fit7)


summary(monthly_income_model_fit8) # Not a good fit
confint(monthly_income_model_fit8)


summary(monthly_income_model_fit9) # This is the best fit!!!!!!! 1071 Fail to reject the Null Hypothesis
confint(monthly_income_model_fit9)

monthly_income_test %>% ggplot(mapping = aes(x = MonthlyIncome, y = TotalWorkingYears))+ 
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)

monthly_income_test %>% ggplot(mapping = aes(x = MonthlyIncome, y = TotalWorkingYears))+ 
  geom_point()+
  geom_line(colour = "red")+
  geom_smooth(method = "lm", se = FALSE)

summary(monthly_income_model_fit10)
confint(monthly_income_model_fit10)

monthly_income_test_mutate %>% ggplot(mapping = aes(x = MonthlyIncome, y = TotalWorkingYears))+ 
  geom_point()+
  geom_line(colour = "red")+
  geom_smooth(method = "lm", se = FALSE)

```


```{r}
employee_data %>% ggplot(mapping = aes(x = MonthlyIncome, y = Department))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")
#cor.test(employee_data$MonthlyIncome, as.factor(employee_data$Department))


employee_data %>% ggplot(mapping = aes(x = MonthlyIncome, y = Age))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")


employee_data %>% ggplot(mapping = aes(x = MonthlyIncome, y = EducationField))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")+
  coord_flip()

employee_data %>% ggplot(mapping = aes(x = MonthlyIncome, y = JobLevel))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")
cor.test(employee_data$MonthlyIncome, employee_data$JobLevel)


employee_data %>% ggplot(mapping = aes(x = MonthlyIncome, y = JobRole))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")+
  coord_flip()

str(employee_data)

cor.test(employee_data$MonthlyIncome, employee_data$YearsAtCompany)

employee_data %>% ggplot(mapping = aes(x = TotalWorkingYears, y = YearsAtCompany, position = "jitters"), position = "jitters")+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")


cor.test(employee_data$MonthlyIncome, employee_data$TotalWorkingYears)

employee_data %>% ggplot(mapping = aes(x = TotalWorkingYears, y = MonthlyIncome))+
  geom_point()+
  geom_smooth(method = "lm" , se = FALSE)+
  ggtitle("Total Years vs. MonthlyIncome")+
  coord_flip()



```


```{r}
# Code on how to break out the training and test data set.

# index <- createDataPartition(adult$Class, p = .70, list = FALSE)
# train <- adult[index, ]
# test <- adult[-index, ]

```

```{r}

employee_data %>% select(Attrition,
 ) %>%
  ggpairs(mapping = aes(color = Attrition))

# Age - potential
# Attrition - throw away
# BusinessTravel - throw away
# DailyRate - throw away
# Department potential
# DistanceFromHome - throw away
# Education - throw away
# EducationField  - potential
# EmployeeCount - throw away
# EmployeeNumber - throw awy
# EnvironmentSatisfaction - Throw away
# Gender - Throw away
# HourlyRate - Throw away
# JobInvolvement - throw away
# JobLevel - potential
# JobRole - potential
# JobSatisfaction - Throw away
# MaritalStatus - throw away
# MonthlyIncome
# MonthlyRate - throw away
# NumCompaniesWorked - throw away
# Over18 - throw away
# OverTime - throw away
# PercentSalaryHike - Throw away
# PerformanceRating - throw away
# RelationshipSatisfaction - Throw away
# StandardHours - throw away
# StockOptionLevel - throw away
# TotalWorkingYears - High potential
# TrainingTimesLastYear - Throw away
# WorkLifeBalance - Throw away
# YearsAtCompany - slight potential
# YearsInCurrentRole  - throw away
# YearsSinceLastPromotion - throw away
# YearsWithCurrManager - throw away


```



#EDA CHUNK
```{r}

# To examine the distribution of a CATEGORICAL variable, use a bar chart
# You can compute these values manually with dplyr::count()
# To examine the distribution of a continuous variable, use a histogram:
# You can compute this by hand by combining dplyr::count() and ggplot2::cut_width():
# Look at overtime and numberofcompanies worked.. there may be a trend there.Why is the average lower for one versus the other.
# Look at the YearswithcurrentManager and YearsatCompany.. something there
# Yearswithcurrentmanager and YearsSinceLastPromotion
# Yearsincurrentrole and YearsSinceLastPromotion


# employee_data %>% select(MonthlyIncome
#   ,JobSatisfaction
#   ,Age
#   ,MaritalStatus          
#   ,MonthlyRate
#   ,NumCompaniesWorked
#   ,Gender
#   ,HourlyRate
#   ,JobInvolvement          
#   ,JobLevel                
#   ,JobRole
#   ,Education               
#   ,EducationField          
#   ,EmployeeCount           
#   ,EmployeeNumber          
#   ,EnvironmentSatisfaction ) %>%
#   ggpairs(mapping = aes(color = Attrition))






ggplot(data = employee_data, mapping = aes(x = MonthlyIncome, y = MonthlyIncome, colour = Attrition)) +
  geom_area()



ggplot(data = employee_data, mapping = aes(x = MonthlyIncome, colour = JobRole)) +
  geom_freqpoly()

# Observation, the people with salary less than $5,000 is greatest among the Research and Development Department, why?
# Are they younger?, Do they have lower job levels, do they work less hours? Did more people leave the company out of the Research & Development department? What department had the highest Attrition?


# Research Scientist are the highest among those making less than $5,000. They start out a little higher than other roles. but only less than 5 are making over $10,000 
ggplot(data = employee_data, mapping = aes(x = MonthlyIncome, colour = JobRole)) +
  geom_freqpoly()
 
employee_data %>% group_by(JobRole) %>% count(MonthlyIncome)

# Monthly Income
ggplot(data = employee_data, mapping = aes(x= JobRole, y = MonthlyIncome, color = Attrition))+
  geom_boxplot()

#How does overtime affect this? 
ggplot(data = employee_data, mapping = aes(x= JobRole, y = MonthlyIncome, color = OverTime))+
  geom_boxplot()

#How many people get overtime by jobrole? Only 65 research scientist gets overtime.
employee_data %>% group_by(JobRole) %>% count(OverTime)


# What does this look like for the daily rate?
ggplot(data = employee_data, mapping = aes(x= JobRole, y = DailyRate, color = Attrition))+
  geom_boxplot()

# What does this look like for the Monthly rate?
ggplot(data = employee_data, mapping = aes(x= JobRole, y = MonthlyRate, color = Attrition))+
  geom_boxplot()


# Attrition is high among those who make less that 5,000. The graph below shows this.
ggplot(data = employee_data, mapping = aes(x = MonthlyIncome, colour = Attrition)) +
  geom_freqpoly()

# The average monthlyIncome was significantly lower in one Education Field than the others? Why?
# The average monthlyIncome was significantly lower in one Department than the others? Why?


ggplot(data = )
ggplot(data = employee_data, mapping = aes(x= EducationField, y = MonthlyRate, color = Attrition))+
  geom_boxplot()

```




# % Experimentation
```{r}

# library( data.table )
# setDT( students )[ , 100 * .N / nrow( students ), by = gender ]
# 
# setDT(employee_data)[, 100* .N/nrow(employee_data), by = Attrition]
# 
# 
# library( dplyr )
# employee_data %>% 
#     group_by( Attrition ) %>% 
#     summarise( percent = 100 * n() / nrow( employee_data ) )
# 
# view(employee_data)

```

