---
title: "Frito Lay Analysis"
author: "Rayon M"
date: "7/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries Used in the Study

```{r echo = FALSE}

library(tidyverse)
library(GGally)
library(naniar)
library(dplyr)
library(class)
library(caret)
library(e1071)
library(ggplot2)
library(plotly)


```

# Dataset provided for use in the Study

```{r echo=FALSE}


# Read in the Employee Dataset that will used in the Analysis.

employee_data = read.csv("C:/Users/Rayon/OneDrive/Documents/Doing DataScience/Doing Data Science/MSDS_6306_Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2-data.csv")


#view(employee_data)

```


# Classification Model
## Naive Bayes

```{r}

# Find the average accuracy, sensitivity, and specificity of the model. The sensitivity and specificity must both be >= 60%.

master_Acc = numeric(100)
master_sensitivity = numeric(100)
master_specificivity = numeric(100)


for(seed in 1:100)
{
  set.seed(seed)
  splitPerc = 0.70
  TrainIndices = sample(1:dim(employee_data)[1],round(splitPerc * dim(employee_data)[1]))
  Train = employee_data[trainIndices,]
  Test = employee_data[-trainIndices,]
  model_attrition_yesorno = naiveBayes(Train[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")],factor(Train$Attrition, labels=c("No", "Yes")))
  CM = confusionMatrix(table(factor(Test$Attrition, labels = c("No", "Yes")), predict(model_attrition_yesorno,Test[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")])))
  master_Acc[seed] = CM$overall[1]
  master_sensitivity[seed] = CM$byClass[1]
  master_specificivity[seed] = CM$byClass[2]
}

mean(master_Acc)
mean(master_sensitivity)
mean(master_specificivity)


# The mean Accuracy is 0.8544061
# The mean Sensitivity is 0.8688525
# The mean Specificity is 0.6470588

```

## Competition Set with No Attrition

```{r echo = FALSE}
#Load in the competition dataset
comp_dataset = read.csv("C:/Users/Rayon/OneDrive/Documents/Doing DataScience/Doing Data Science/MSDS_6306_Doing-Data-Science/Unit 14 and 15 Case Study 2/CaseStudy2CompSet No Attrition.csv")

#Use the Naive Bayes Classification Model to classify each observation as Yes or No to Attrition.
# Model name = "model_attrition_yesorno"

comp_dataset$Attrition =  predict(model_attrition_yesorno,comp_dataset[,c("Age", "JobLevel", "MonthlyIncome", "OverTime")])

view(comp_dataset)

write.csv(comp_dataset, "Case2PredictionsMorris Attrition.csv")


```



## Regression Model

```{r}


employeeData %>% ggplot(mapping = aes(x = MonthlyIncome, y = Age)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)


employeeData %>% ggplot(mapping = aes(x = MonthlyIncome, y = JobLevel)) +
  geom_point()

employeeData %>% ggplot(mapping = aes(x = MonthlyIncome)) +
  geom_histogram(binwidth = 10000)
 

employeeData %>% ggplot(mapping = aes(x = MonthlyIncome, y = Age)) +
  geom_point
  
employeeData %>% ggplot(mapping = aes(x = MonthlyIncome, y = JobLevel)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)

fit = lm(MonthlyIncome~JobLevel, data = employeeData)

#predict(fit, newdata =x,interval = "confidence")

preds = predict(fit)
preds

employeeData$predMI = preds

summary(fit)
confint(fit)

fit$coefficients


AttritionModel = lm(Attrition~Age+MonthlyIncome, data = employeeDataAtt)

predsss = predict(AttritionModel)

predsss

as.numeric(Attrition)

view(employeeData)


ggplot(data = employeeData, mapping = aes(x = MonthlyIncome, y = predMI))+
  geom_point()

#response variable goes into the lm model first


require(dplyr)
employeeDataAtt <- employeeData %>%
      mutate(Attrition = ifelse(Attrition == "No",0,1))

view(employeeDataAtt)
```
